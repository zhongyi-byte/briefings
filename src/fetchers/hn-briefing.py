#!/usr/bin/env python3
"""
Hacker News ç®€æŠ¥ç”Ÿæˆå™¨
æŠ“å– Top Storiesï¼Œä¼˜å…ˆ AI/æŠ•èµ„ç›¸å…³è¯é¢˜
"""

import json
import urllib.request
import socket
from datetime import datetime
from pathlib import Path

socket.setdefaulttimeout(15)

AI_KEYWORDS = [
    'ai', 'llm', 'gpt', 'claude', 'openai', 'anthropic', 'gemini', 
    'machine learning', 'deep learning', 'neural',
    'investment', 'trading', 'crypto', 'stock', 'market',
    'startup', 'venture', 'funding'
]

def fetch_hn(limit=10):
    """è·å– Hacker News Top Stories"""
    print("ğŸ” è·å– Hacker News...")
    
    try:
        url = "https://hacker-news.firebaseio.com/v0/topstories.json"
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=10) as r:
            story_ids = json.loads(r.read())[:limit * 2]
        
        stories = []
        for sid in story_ids[:limit]:
            try:
                surl = f"https://hacker-news.firebaseio.com/v0/item/{sid}.json"
                req = urllib.request.Request(surl, headers={'User-Agent': 'Mozilla/5.0'})
                with urllib.request.urlopen(req, timeout=5) as r:
                    story = json.loads(r.read())
                
                if story and story.get('title'):
                    title = story['title'].lower()
                    score = story.get('score', 0)
                    
                    is_ai = any(kw in title for kw in AI_KEYWORDS)
                    priority = 1 if is_ai else 2
                    
                    stories.append({
                        'title': story['title'],
                        'url': story.get('url', f"https://news.ycombinator.com/item?id={sid}"),
                        'score': score,
                        'comments': story.get('descendants', 0),
                        'priority': priority,
                        'is_ai': is_ai
                    })
            except:
                continue
        
        stories.sort(key=lambda x: (x['priority'], -x['score']))
        print(f"   âœ… {len(stories)} æ¡")
        return stories
    
    except Exception as e:
        print(f"   âŒ {e}")
        return []

def generate_briefing(stories):
    """ç”Ÿæˆ HN ç®€æŠ¥"""
    date_str = datetime.now().strftime('%Y-%m-%d')
    
    md = f"""# ğŸ”¥ Hacker News ç®€æŠ¥ - {date_str}

> æ¥æº: Hacker News Top Stories
> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%H:%M')}
> å…± {len(stories)} æ¡

---

"""
    
    ai_stories = [s for s in stories if s.get('is_ai')]
    other_stories = [s for s in stories if not s.get('is_ai')]
    
    if ai_stories:
        md += "## ğŸ¤– AI/æŠ•èµ„ç›¸å…³\n\n"
        for s in ai_stories:
            md += f"- **[{s['title']}]({s['url']})**  \n"
            md += f"  ğŸ’¬ {s['comments']} | â¬†ï¸ {s['score']}\n\n"
    
    if other_stories:
        md += "## ğŸ“° å…¶ä»–çƒ­é—¨\n\n"
        for s in other_stories[:6]:
            md += f"- [{s['title']}]({s['url']})  \n"
            md += f"  ğŸ’¬ {s['comments']} | â¬†ï¸ {s['score']}\n\n"
    
    md += f"""---

*ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}*
*æ¥æº: [Hacker News](https://news.ycombinator.com)*
"""
    return md

def main():
    print("=" * 60)
    print("ğŸ”¥ Hacker News ç®€æŠ¥ç”Ÿæˆå™¨")
    print("=" * 60)
    print()
    
    stories = fetch_hn()
    
    if not stories:
        print("âŒ æœªè·å–åˆ°æ•°æ®")
        return
    
    briefing = generate_briefing(stories)
    
    # ä¿å­˜
    output_dir = Path(__file__).parent.parent.parent / "output"
    output_dir.mkdir(exist_ok=True)
    output_path = output_dir / f"hn-briefing-{datetime.now().strftime('%Y-%m-%d')}.md"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(briefing)
    
    print(f"\nğŸ’¾ å·²ä¿å­˜: {output_path}")
    print(f"ğŸ“Š AIç›¸å…³: {len([s for s in stories if s['is_ai']])} æ¡")

if __name__ == "__main__":
    main()
