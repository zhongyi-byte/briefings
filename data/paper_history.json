{
  "papers": [
    {
      "id": "http://arxiv.org/abs/2602.13197v1",
      "title": "Imitating What Works: Simulation-Filtered Modular Policy Learning from Human Videos",
      "summary": "The ability to learn manipulation skills by watching videos of humans has the potential to unlock a new source of highly scalable data for robot learning. Here, we tackle prehensile manipulation, in which tasks involve grasping an object before performing various post-grasp motions. Human videos offer strong signals for learning the post-grasp motions, but they are less useful for learning the prerequisite grasping behaviors, especially for robots without human-like hands. A promising way forward is to use a modular policy design, leveraging a dedicated grasp generator to produce stable grasps. However, arbitrary stable grasps are often not task-compatible, hindering the robot's ability to perform the desired downstream motion. To address this challenge, we present Perceive-Simulate-Imitate (PSI), a framework for training a modular manipulation policy using human video motion data processed by paired grasp-trajectory filtering in simulation. This simulation step extends the trajectory data with grasp suitability labels, which allows for supervised learning of task-oriented grasping capabilities. We show through real-world experiments that our framework can be used to learn precise manipulation skills efficiently without any robot data, resulting in significantly more robust performance than using a grasp generator naively.",
      "published": "2026-02-13T18:59:10Z",
      "updated": "2026-02-13T18:59:10Z",
      "authors": [
        "Albert J. Zhai",
        "Kuo-Hao Zeng",
        "Jiasen Lu",
        "Ali Farhadi",
        "Shenlong Wang",
        "Wei-Chiu Ma"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13197v1",
      "primary_category": "cs.RO",
      "classification": {
        "labs": [
          "Anthropic",
          "DeepMind"
        ],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13195v1",
      "title": "Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision",
      "summary": "Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., \"left-most apple\") and overlooks functional and physical reasoning (e.g., \"where can I safely store the knife?\"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding, and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/",
      "published": "2026-02-13T18:58:30Z",
      "updated": "2026-02-13T18:58:30Z",
      "authors": [
        "Aadarsh Sahoo",
        "Georgia Gkioxari"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13195v1",
      "primary_category": "cs.CV",
      "classification": {
        "labs": [],
        "topics": [
          "Reasoning"
        ],
        "priority": "medium"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13193v1",
      "title": "Steerable Vision-Language-Action Policies for Embodied Reasoning and Hierarchical Control",
      "summary": "Pretrained vision-language models (VLMs) can make semantic and visual inferences across diverse settings, providing valuable common-sense priors for robotic control. However, effectively grounding this knowledge in robot behaviors remains an open challenge. Prior methods often employ a hierarchical approach where VLMs reason over high-level commands to be executed by separate low-level policies, e.g., vision-language-action models (VLAs). The interface between VLMs and VLAs is usually natural language task instructions, which fundamentally limits how much VLM reasoning can steer low-level behavior. We thus introduce Steerable Policies: VLAs trained on rich synthetic commands at various levels of abstraction, like subtasks, motions, and grounded pixel coordinates. By improving low-level controllability, Steerable Policies can unlock pretrained knowledge in VLMs, enabling improved task generalization. We demonstrate this benefit by controlling our Steerable Policies with both a learned high-level embodied reasoner and an off-the-shelf VLM prompted to reason over command abstractions via in-context learning. Across extensive real-world manipulation experiments, these two novel methods outperform prior embodied reasoning VLAs and VLM-based hierarchical baselines, including on challenging generalization and long-horizon tasks.\n  Website: steerable-policies.github.io",
      "published": "2026-02-13T18:57:56Z",
      "updated": "2026-02-13T18:57:56Z",
      "authors": [
        "William Chen",
        "Jagdeep Singh Bhatia",
        "Catherine Glossop",
        "Nikhil Mathihalli",
        "Ria Doshi",
        "Andy Tang",
        "Danny Driess",
        "Karl Pertsch",
        "Sergey Levine"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13193v1",
      "primary_category": "cs.RO",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [
          "Learning & Education",
          "Reasoning"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13191v1",
      "title": "CoPE-VideoLM: Codec Primitives For Efficient Video Language Models",
      "summary": "Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to $86\\%$ and token usage by up to $93\\%$ compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on $14$ diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding.",
      "published": "2026-02-13T18:57:31Z",
      "updated": "2026-02-13T18:57:31Z",
      "authors": [
        "Sayan Deb Sarkar",
        "Rémi Pautrat",
        "Ondrej Miksik",
        "Marc Pollefeys",
        "Iro Armeni",
        "Mahdi Rad",
        "Mihai Dusmanu"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13191v1",
      "primary_category": "cs.CV",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [
          "Reasoning"
        ],
        "priority": "medium"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13190v1",
      "title": "Disorder viscosity correction approach to calculate spinodal temperature and wavelength",
      "summary": "Spinodal decomposition, a key mechanism to microstructure formation in materials, has long posed challenges for predictive modeling, due to the need for parameter-free approaches that accurately capture local energy landscapes. In this work, we propose an approach to predict spinodal behavior by introducing a disorder viscosity correction to bulk free energies computed from finite, small, representative cells. We approximate the energy penalty required to transition into a disordered state to enable the stabilization of locally concave bulk free energy regions - essential for interface formation - while suppressing long-range concentration fluctuations. This approximation circumvents the complexity of full ab initio parameterization of interfacial properties and is well-suited for high-throughput and machine-learning frameworks. Our approach captures the necessary physics underpinning spinodal kinetics, offering a scalable route to predict spinodal regions in compositionally complex and high-entropy materials.",
      "published": "2026-02-13T18:56:21Z",
      "updated": "2026-02-13T18:56:21Z",
      "authors": [
        "Simon Divilov",
        "Hagen Eckert",
        "Nico Hotz",
        "Xiomara Campilongo",
        "Stefano Curtarolo"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13190v1",
      "primary_category": "cond-mat.mtrl-sci",
      "classification": {
        "labs": [
          "Meta AI"
        ],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13187v1",
      "title": "Nuclear gradients from auxiliary-field quantum Monte Carlo and their application in geometry optimization and transition state search",
      "summary": "In this article, we present a method for computing accurate and scalable nuclear forces within the phaseless auxiliary-field quantum Monte Carlo (AFQMC) framework. Our approach leverages automatic differentiation of the energy functional to obtain nuclear gradients at a computational cost comparable to that of energy evaluation. The accuracy of the method is validated against finite difference calculations, showing excellent agreement. We then explore several machine learning (ML) strategies for learning noisy AFQMC data. These ML potentials are subsequently used to perform geometry optimizations and nudged elastic band (NEB) calculations, successfully identifying the transition state of the formamide-formimidic acid tautomerization. The resulting transition state geometry and barrier heights are in close agreement with coupled-cluster reference values. This work paves the way for highly accurate geometry optimization, molecular dynamics, or reaction path calculations.",
      "published": "2026-02-13T18:53:55Z",
      "updated": "2026-02-13T18:53:55Z",
      "authors": [
        "Jo S. Kurian",
        "Ankit Mahajan",
        "Sandeep Sharma"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13187v1",
      "primary_category": "physics.chem-ph",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13184v1",
      "title": "Profiling systematic uncertainties in Simulation-Based Inference with Factorizable Normalizing Flows",
      "summary": "Unbinned likelihood fits aim at maximizing the information one can extract from experimental data, yet their application in realistic statistical analyses is often hindered by the computational cost of profiling systematic uncertainties. Additionally, current machine learning-based inference methods are typically limited to estimating scalar parameters in a multidimensional space rather than full differential distributions. We propose a general framework for Simulation-Based Inference (SBI) that efficiently profiles nuisance parameters while measuring multivariate Distributions of Interest (DoI), defined as learnable invertible transformations of the feature space. We introduce Factorizable Normalizing Flows to model systematic variations as parametric deformations of a nominal density, preserving tractability without combinatorial explosion. Crucially, we develop an amortized training strategy that learns the conditional dependence of the DoI on nuisance parameters in a single optimization process, bypassing the need for repetitive training during the likelihood scan. This allows for the simultaneous extraction of the underlying distribution and the robust profiling of nuisances. The method is validated on a synthetic dataset emulating a high-energy physics measurement with multiple systematic sources, demonstrating its potential for unbinned, functional measurements in complex analyses.",
      "published": "2026-02-13T18:48:12Z",
      "updated": "2026-02-13T18:48:12Z",
      "authors": [
        "Davide Valsecchi",
        "Mauro Donegà",
        "Rainer Wallny"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13184v1",
      "primary_category": "hep-ph",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13181v1",
      "title": "Selection of CMIP6 Models for Regional Precipitation Projection and Climate Change Assessment in the Jhelum and Chenab River Basins",
      "summary": "Effective water resource management depends on accurate projections of flows in water channels. For projected climate data, use of different General Circulation Models (GCM) simulates contrasting results. This study shows selection of GCM for the latest generation CMIP6 for hydroclimate change impact studies. Envelope based method was used for the selection, which includes components based on machine learning techniques, allowing the selection of GCMs without the need for in-situ reference data. According to our knowledge, for the first time, such a comparison was performed for the CMIP6 Shared Socioeconomic Pathway (SSP) scenarios data. In addition, the effect of climate change under SSP scenarios was studied, along with the calculation of extreme indices. Finally, GCMs were compared to quantify spatiotemporal differences between CMIP5 and CMIP6 data. Results provide NorESM2 LM, FGOALS g3 as selected models for the Jhelum and Chenab River. Highly vulnerable regions under the effect of climate change were highlighted through spatial maps, which included parts of Punjab, Jammu, and Kashmir. Upon comparison of CMIP5 and CMIP6, no discernible difference was found between the RCP and SSP scenarios precipitation projections. In the future, more detailed statistical comparisons could further reinforce the proposition.",
      "published": "2026-02-13T18:41:40Z",
      "updated": "2026-02-13T18:41:40Z",
      "authors": [
        "Saad Ahmed Jamal",
        "Ammara Nusrat",
        "Muhammad Azmat",
        "Muhammad Osama Nusrat"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13181v1",
      "primary_category": "physics.ao-ph",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13179v1",
      "title": "Fix Before Search: Benchmarking Agentic Query Visual Pre-processing in Multimodal Retrieval-augmented Generation",
      "summary": "Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a key paradigm for grounding MLLMs with external knowledge. While query pre-processing (e.g., rewriting) is standard in text-based RAG, existing MRAG pipelines predominantly treat visual inputs as static and immutable, implicitly assuming they are noise-free. However, real-world visual queries are often ``imperfect'' -- suffering from geometric distortions, quality degradation, or semantic ambiguity -- leading to catastrophic retrieval failures. To address this gap, we propose V-QPP-Bench, the first comprehensive benchmark dedicated to Visual Query Pre-processing (V-QPP). We formulate V-QPP as an agentic decision-making task where MLLMs must autonomously diagnose imperfections and deploy perceptual tools to refine queries. Our extensive evaluation across 46,700 imperfect queries and diverse MRAG paradigms reveals three critical insights: (1) Vulnerability -- visual imperfections severely degrade both retrieval recall and end-to-end MRAG performance; (2) Restoration Potential \\& Bottleneck -- while oracle preprocessing recovers near-perfect performance, off-the-shelf MLLMs struggle with tool selection and parameter prediction without specialized training; and (3) Training Enhancement -- supervised fine-tuning enables compact models to achieve comparable or superior performance to larger proprietary models, demonstrating the benchmark's value for developing robust MRAG systems The code is available at https://github.com/phycholosogy/VQQP_Bench",
      "published": "2026-02-13T18:39:48Z",
      "updated": "2026-02-13T18:39:48Z",
      "authors": [
        "Jiankun Zhang",
        "Shenglai Zeng",
        "Kai Guo",
        "Xinnan Dai",
        "Hui Liu",
        "Jiliang Tang",
        "Yi Chang"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13179v1",
      "primary_category": "cs.IR",
      "classification": {
        "labs": [
          "Anthropic"
        ],
        "topics": [
          "AI Agents & Delegation"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13174v1",
      "title": "Learning functional components of PDEs from data using neural networks",
      "summary": "Partial differential equations often contain unknown functions that are difficult or impossible to measure directly, hampering our ability to derive predictions from the model. Workflows for recovering scalar PDE parameters from data are well studied: here we show how similar workflows can be used to recover functions from data. Specifically, we embed neural networks into the PDE and show how, as they are trained on data, they can approximate unknown functions with arbitrary accuracy. Using nonlocal aggregation-diffusion equations as a case study, we recover interaction kernels and external potentials from steady state data. Specifically, we investigate how a wide range of factors, such as the number of available solutions, their properties, sampling density, and measurement noise, affect our ability to successfully recover functions. Our approach is advantageous because it can utilise standard parameter-fitting workflows, and in that the trained PDE can be treated as a normal PDE for purposes such as generating system predictions.",
      "published": "2026-02-13T18:32:33Z",
      "updated": "2026-02-13T18:32:33Z",
      "authors": [
        "Torkel E. Loman",
        "Yurij Salmaniw",
        "Antonio Leon Villares",
        "Jose A. Carrillo",
        "Ruth E. Baker"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13174v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13172v1",
      "title": "LongStream: Long-Sequence Streaming Autoregressive Visual Geometry",
      "summary": "Long-sequence streaming 3D reconstruction remains a significant open challenge. Existing autoregressive models often fail when processing long sequences. They typically anchor poses to the first frame, which leads to attention decay, scale drift, and extrapolation errors. We introduce LongStream, a novel gauge-decoupled streaming visual geometry model for metric-scale scene reconstruction across thousands of frames. Our approach is threefold. First, we discard the first-frame anchor and predict keyframe-relative poses. This reformulates long-range extrapolation into a constant-difficulty local task. Second, we introduce orthogonal scale learning. This method fully disentangles geometry from scale estimation to suppress drift. Finally, we solve Transformer cache issues such as attention-sink reliance and long-term KV-cache contamination. We propose cache-consistent training combined with periodic cache refresh. This approach suppresses attention degradation over ultra-long sequences and reduces the gap between training and inference. Experiments show LongStream achieves state-of-the-art performance. It delivers stable, metric-scale reconstruction over kilometer-scale sequences at 18 FPS. Project Page: https://3dagentworld.github.io/longstream/",
      "published": "2026-02-13T18:30:51Z",
      "updated": "2026-02-13T18:30:51Z",
      "authors": [
        "Chong Cheng",
        "Xianda Chen",
        "Tao Xie",
        "Wei Yin",
        "Weiqiang Ren",
        "Qian Zhang",
        "Xiaoyuang Guo",
        "Hao Wang"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13172v1",
      "primary_category": "cs.CV",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [
          "AI Agents & Delegation",
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13169v1",
      "title": "Operator Learning for Families of Finite-State Mean-Field Games",
      "summary": "Finite-state mean-field games (MFGs) arise as limits of large interacting particle systems and are governed by an MFG system, a coupled forward-backward differential equation consisting of a forward Kolmogorov-Fokker-Planck (KFP) equation describing the population distribution and a backward Hamilton-Jacobi-Bellman (HJB) equation defining the value function. Solving MFG systems efficiently is challenging, with the structure of each system depending on an initial distribution of players and the terminal cost of the game. We propose an operator learning framework that solves parametric families of MFGs, enabling generalization without retraining for new initial distributions and terminal costs. We provide theoretical guarantees on the approximation error, parametric complexity, and generalization performance of our method, based on a novel regularity result for an appropriately defined flow map corresponding to an MFG system. We demonstrate empirically that our framework achieves accurate approximation for two representative instances of MFGs: a cybersecurity example and a high-dimensional quadratic model commonly used as a benchmark for numerical methods for MFGs.",
      "published": "2026-02-13T18:28:34Z",
      "updated": "2026-02-13T18:28:34Z",
      "authors": [
        "William Hofgard",
        "Asaf Cohen",
        "Mathieu Laurière"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13169v1",
      "primary_category": "math.OC",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13168v1",
      "title": "Realistic Face Reconstruction from Facial Embeddings via Diffusion Models",
      "summary": "With the advancement of face recognition (FR) systems, privacy-preserving face recognition (PPFR) systems have gained popularity for their accurate recognition, enhanced facial privacy protection, and robustness to various attacks. However, there are limited studies to further verify privacy risks by reconstructing realistic high-resolution face images from embeddings of these systems, especially for PPFR. In this work, we propose the face embedding mapping (FEM), a general framework that explores Kolmogorov-Arnold Network (KAN) for conducting the embedding-to-face attack by leveraging pre-trained Identity-Preserving diffusion model against state-of-the-art (SOTA) FR and PPFR systems. Based on extensive experiments, we verify that reconstructed faces can be used for accessing other real-word FR systems. Besides, the proposed method shows the robustness in reconstructing faces from the partial and protected face embeddings. Moreover, FEM can be utilized as a tool for evaluating safety of FR and PPFR systems in terms of privacy leakage. All images used in this work are from public datasets.",
      "published": "2026-02-13T18:28:24Z",
      "updated": "2026-02-13T18:28:24Z",
      "authors": [
        "Dong Han",
        "Yong Li",
        "Joachim Denzler"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13168v1",
      "primary_category": "cs.CV",
      "classification": {
        "labs": [
          "DeepMind",
          "Google Research"
        ],
        "topics": [],
        "priority": "low"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13165v1",
      "title": "Asynchronous Verified Semantic Caching for Tiered LLM Architectures",
      "summary": "Large language models (LLMs) now sit in the critical path of search, assistance, and agentic workflows, making semantic caching essential for reducing inference cost and latency. Production deployments typically use a tiered static-dynamic design: a static cache of curated, offline vetted responses mined from logs, backed by a dynamic cache populated online. In practice, both tiers are commonly governed by a single embedding similarity threshold, which induces a hard tradeoff: conservative thresholds miss safe reuse opportunities, while aggressive thresholds risk serving semantically incorrect responses. We introduce \\textbf{Krites}, an asynchronous, LLM-judged caching policy that expands static coverage without changing serving decisions. On the critical path, Krites behaves exactly like a standard static threshold policy. When the nearest static neighbor of the prompt falls just below the static threshold, Krites asynchronously invokes an LLM judge to verify whether the static response is acceptable for the new prompt. Approved matches are promoted into the dynamic cache, allowing future repeats and paraphrases to reuse curated static answers and expanding static reach over time. In trace-driven simulations on conversational and search workloads, Krites increases the fraction of requests served with curated static answers (direct static hits plus verified promotions) by up to $\\textbf{3.9}$ times for conversational traffic and search-style queries relative to tuned baselines, with unchanged critical path latency.",
      "published": "2026-02-13T18:25:00Z",
      "updated": "2026-02-13T18:25:00Z",
      "authors": [
        "Asmit Kumar Singh",
        "Haozhe Wang",
        "Laxmi Naga Santosh Attaluri",
        "Tak Chiam",
        "Weihua Zhu"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13165v1",
      "primary_category": "cs.IR",
      "classification": {
        "labs": [],
        "topics": [
          "AI Agents & Delegation"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13164v1",
      "title": "Early-warning the compact-to-dendritic transition via spatiotemporal learning of two-dimensional growth images",
      "summary": "Transitions between distinct dynamical regimes are ubiquitous in nonequilibrium systems. As a prototypical example, deposition growth is often accompanied by irreversible morphological instabilities. Forecasting such transitions from pre-transition configurations remains fundamentally challenging, as early precursors are weak, spatially heterogeneous, and masked by inherent fluctuations. Here, we investigate compact-to-dendritic transitions (CDTs) in a two-dimensional particle-based electrodeposition model and formulate a horizon-based early-warning task using trajectory-resolved transition points. We demonstrate that anticipating the CDT is intrinsically a spatiotemporal problem: neither static morphological descriptors nor temporal learning applied to predefined features alone yields reliable predictive signals. In contrast, end-to-end learning of jointly optimized spatial and temporal representations from growth images enables robust anticipation across a wide range of prediction horizons. Analysis of the learned latent dynamics reveals the emergence of a low-dimensional surrogate variable that tracks progressive morphological destabilization and undergoes reorganization near the transition. We further show that the learned spatiotemporal representation exhibits limited but systematic transferability across reaction-rate conditions, with predictive performance degrading as the inference condition departs from the training condition, consistent with changes in the latent-state dynamics. Overall, our results establish a general formulation for forecasting incipient instabilities in nonequilibrium interfacial growth, with implications for the predictive monitoring and control of pattern-forming driven systems.",
      "published": "2026-02-13T18:23:36Z",
      "updated": "2026-02-13T18:23:36Z",
      "authors": [
        "Hyunjun Jang",
        "Chung Bin Park",
        "Jeonghoon Kim",
        "Jeongmin Kim"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13164v1",
      "primary_category": "physics.chem-ph",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13156v1",
      "title": "In-Context Autonomous Network Incident Response: An End-to-End Large Language Model Agent Approach",
      "summary": "Rapidly evolving cyberattacks demand incident response systems that can autonomously learn and adapt to changing threats. Prior work has extensively explored the reinforcement learning approach, which involves learning response strategies through extensive simulation of the incident. While this approach can be effective, it requires handcrafted modeling of the simulator and suppresses useful semantics from raw system logs and alerts. To address these limitations, we propose to leverage large language models' (LLM) pre-trained security knowledge and in-context learning to create an end-to-end agentic solution for incident response planning. Specifically, our agent integrates four functionalities, perception, reasoning, planning, and action, into one lightweight LLM (14b model). Through fine-tuning and chain-of-thought reasoning, our LLM agent is capable of processing system logs and inferring the underlying network state (perception), updating its conjecture of attack models (reasoning), simulating consequences under different response strategies (planning), and generating an effective response (action). By comparing LLM-simulated outcomes with actual observations, the LLM agent repeatedly refines its attack conjecture and corresponding response, thereby demonstrating in-context adaptation. Our agentic approach is free of modeling and can run on commodity hardware. When evaluated on incident logs reported in the literature, our agent achieves recovery up to 23% faster than those of frontier LLMs.",
      "published": "2026-02-13T18:09:30Z",
      "updated": "2026-02-13T18:09:30Z",
      "authors": [
        "Yiran Gao",
        "Kim Hammar",
        "Tao Li"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13156v1",
      "primary_category": "cs.CR",
      "classification": {
        "labs": [
          "DeepMind"
        ],
        "topics": [
          "AI Agents & Delegation",
          "Learning & Education",
          "Reasoning"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13155v1",
      "title": "Learning to Approximate Uniform Facility Location via Graph Neural Networks",
      "summary": "There has been a growing interest in using neural networks, especially message-passing neural networks (MPNNs), to solve hard combinatorial optimization problems heuristically. However, existing learning-based approaches for hard combinatorial optimization tasks often rely on supervised training data, reinforcement learning, or gradient estimators, leading to significant computational overhead, unstable training, or a lack of provable performance guarantees. In contrast, classical approximation algorithms offer such performance guarantees under worst-case inputs but are non-differentiable and unable to adaptively exploit structural regularities in natural input distributions. We address this dichotomy with the fundamental example of Uniform Facility Location (UniFL), a variant of the combinatorial facility location problem with applications in clustering, data summarization, logistics, and supply chain design. We develop a fully differentiable MPNN model that embeds approximation-algorithmic principles while avoiding the need for solver supervision or discrete relaxations. Our approach admits provable approximation and size generalization guarantees to much larger instances than seen during training. Empirically, we show that our approach outperforms standard non-learned approximation algorithms in terms of solution quality, closing the gap with computationally intensive integer linear programming approaches. Overall, this work provides a step toward bridging learning-based methods and approximation algorithms for discrete optimization.",
      "published": "2026-02-13T18:08:23Z",
      "updated": "2026-02-13T18:08:23Z",
      "authors": [
        "Chendi Qian",
        "Christopher Morris",
        "Stefanie Jegelka",
        "Christian Sohler"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13155v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "DeepMind",
          "Meta AI",
          "Google Research"
        ],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13154v1",
      "title": "Peaceful Anarcho-Accelerationism: Decentralized Full Automation for a Society of Universal Care",
      "summary": "The convergence of large language models that automate cognitive labor and deep reinforcement learning agents that automate physical labor implies the near-complete elimination of human employment. The universal approximation theorem and foundational DRL results establish that all labor is in principle automatable. The critical question is not whether full automation will arrive, but who will control it. This paper introduces peaceful anarcho-accelerationism: a sociotechnical framework ensuring that full automation is decentralized, commons-governed, and oriented toward universal care. We propose the Liberation Stack, a layered architecture of energy, manufacturing, food, communication, knowledge, and governance commons built on open-source technologies. We show that this framework builds bridges with liberalism, socialism, environmentalism, feminism, cooperativism, and the hacker ethic. Empirical evidence from Linux, Wikipedia, Mondragon, Rojava, and guifi.net confirms that commons-based systems already operate at scale. We argue that full automation renders money obsolete and propose Universal Desired Resources (UDR), a post-monetary design principle where every person requests what they need from the robotic commons, constrained only by ecological sustainability. Drawing on the independence of phenomenal consciousness from computational intelligence, we establish that delegating labor to non-conscious machines is care at civilizational scale, and that moral policy can be studied through deep reinforcement learning. We conclude with a phased roadmap toward the care-centered society, including milestones, assumptions, and limitations.",
      "published": "2026-02-13T18:07:57Z",
      "updated": "2026-02-13T18:07:57Z",
      "authors": [
        "Eduardo C. Garrido-Merchán"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13154v1",
      "primary_category": "cs.CY",
      "classification": {
        "labs": [
          "DeepMind"
        ],
        "topics": [
          "AI Agents & Delegation",
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13151v1",
      "title": "Quantization-Robust LLM Unlearning via Low-Rank Adaptation",
      "summary": "Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment.",
      "published": "2026-02-13T18:01:40Z",
      "updated": "2026-02-13T18:01:40Z",
      "authors": [
        "João Vitor Boer Abitante",
        "Joana Meneguzzo Pasquali",
        "Luan Fonseca Garcia",
        "Ewerton de Oliveira",
        "Thomas da Silva Paula",
        "Rodrigo C. Barros",
        "Lucas S. Kupssinskü"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13151v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Meta AI"
        ],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13145v1",
      "title": "Single snapshot non-Markovianity of Pauli channels",
      "summary": "Pauli channels are widely used to describe errors in quantum computers, particularly when noise is shaped via Pauli twirling. A common assumption is that such channels admit a Markovian generator, namely a Pauli-Lindblad model with non-negative rates, but the validity of this assumption has not been systematically examined. Here, using CP-indivisibility as our criterion for non-Markovianity, we study multi-qubit Pauli channels from a single snapshot of the dynamics. We find that while the generator always has the same structure as the standard Pauli-Lindblad model, the rates may be negative or complex. We show that random Pauli channels are almost always non-Markovian, with the probability of encountering a negative rate converging doubly exponentially to unity with the number of qubits. For physically motivated noise models shaped by Pauli twirling, including single-qubit over-rotations and two-qubit amplitude damping errors, we find that negative rates are generic, even when the underlying physical noise is Markovian. We generalize probabilistic error amplification and cancellation to non-Markovian generators, and quantify the sampling overhead introduced by negative and complex rates. Experiments on superconducting qubits confirm that allowing negative rates in the learned noise model yields more accurate predictions than restricting to non-negative rates.",
      "published": "2026-02-13T17:55:34Z",
      "updated": "2026-02-13T17:55:34Z",
      "authors": [
        "Alireza Seif",
        "Moein Malekakhlagh",
        "Swarnadeep Majumder Luke C. G. Govia"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13145v1",
      "primary_category": "quant-ph",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [],
        "priority": "low"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13140v1",
      "title": "FlashSchNet: Fast and Accurate Coarse-Grained Neural Network Molecular Dynamics",
      "summary": "Graph neural network (GNN) potentials such as SchNet improve the accuracy and transferability of molecular dynamics (MD) simulation by learning many-body interactions, but remain slower than classical force fields due to fragmented kernels and memory-bound pipelines that underutilize GPUs. We show that a missing principle is making GNN-MD IO-aware, carefully accounting for reads and writes between GPU high-bandwidth memory (HBM) and on-chip SRAM. We present FlashSchNet, an efficient and accurate IO-aware SchNet-style GNN-MD framework built on four techniques: (1) flash radial basis, which fuses pairwise distance computation, Gaussian basis expansion, and cosine envelope into a single tiled pass, computing each distance once and reusing it across all basis functions; (2) flash message passing, which fuses cutoff, neighbor gather, filter multiplication, and reduction to avoid materializing edge tensors in HBM; (3) flash aggregation, which reformulates scatter-add via CSR segment reduce, reducing atomic writes by a factor of feature dimension and enabling contention-free accumulation in both forward and backward passes; (4) channel-wise 16-bit quantization that exploits the low per-channel dynamic range in SchNet MLP weights to further improve throughput with negligible accuracy loss. On a single NVIDIA RTX PRO 6000, FlashSchNet achieves 1000 ns/day aggregate simulation throughput over 64 parallel replicas on coarse-grained (CG) protein containing 269 beads (6.5x faster than CGSchNet baseline with 80% reduction of peak memory), surpassing classical force fields (e.g. MARTINI) while retaining SchNet-level accuracy and transferability.",
      "published": "2026-02-13T17:49:12Z",
      "updated": "2026-02-13T17:49:12Z",
      "authors": [
        "Pingzhi Li",
        "Hongxuan Li",
        "Zirui Liu",
        "Xingcheng Lin",
        "Tianlong Chen"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13140v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13136v1",
      "title": "Order Matters in Retrosynthesis: Structure-aware Generation via Reaction-Center-Guided Discrete Flow Matching",
      "summary": "Template-free retrosynthesis methods treat the task as black-box sequence generation, limiting learning efficiency, while semi-template approaches rely on rigid reaction libraries that constrain generalization. We address this gap with a key insight: atom ordering in neural representations matters. Building on this insight, we propose a structure-aware template-free framework that encodes the two-stage nature of chemical reactions as a positional inductive bias. By placing reaction center atoms at the sequence head, our method transforms implicit chemical knowledge into explicit positional patterns that the model can readily capture. The proposed RetroDiT backbone, a graph transformer with rotary position embeddings, exploits this ordering to prioritize chemically critical regions. Combined with discrete flow matching, our approach decouples training from sampling and enables generation in 20--50 steps versus 500 for prior diffusion methods. Our method achieves state-of-the-art performance on both USPTO-50k (61.2% top-1) and the large-scale USPTO-Full (51.3% top-1) with predicted reaction centers. With oracle centers, performance reaches 71.1% and 63.4% respectively, surpassing foundation models trained on 10 billion reactions while using orders of magnitude less data. Ablation studies further reveal that structural priors outperform brute-force scaling: a 280K-parameter model with proper ordering matches a 65M-parameter model without it.",
      "published": "2026-02-13T17:39:21Z",
      "updated": "2026-02-13T17:39:21Z",
      "authors": [
        "Chenguang Wang",
        "Zihan Zhou",
        "Lei Bai",
        "Tianshu Yu"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13136v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13134v1",
      "title": "Awakening Dormant Users: Generative Recommendation with Counterfactual Functional Role Reasoning",
      "summary": "Awakening dormant users, who remain engaged but exhibit low conversion, is a pivotal driver for incremental GMV growth in large-scale e-commerce platforms. However, existing approaches often yield suboptimal results since they typically rely on single-step estimation of an item's intrinsic value (e.g., immediate click probability). This mechanism overlooks the instrumental effect of items, where specific interactions act as triggers to shape latent intent and drive subsequent decisions along a conversion trajectory. To bridge this gap, we propose RoleGen, a novel framework that synergizes a Conversion Trajectory Reasoner with a Generative Behavioral Backbone. Specifically, the LLM-based Reasoner explicitly models the context-dependent Functional Role of items to reconstruct intent evolution. It further employs counterfactual inference to simulate diverse conversion paths, effectively mitigating interest collapse. These reasoned candidate items are integrated into the generative backbone, which is optimized via a collaborative \"Reasoning-Execution-Feedback-Reflection\" closed-loop strategy to ensure grounded execution. Extensive offline experiments and online A/B testing on the Kuaishou e-commerce platform demonstrate that RoleGen achieves a 6.2% gain in Recall@1 and a 7.3% increase in online order volume, confirming its effectiveness in activating the dormant user base.",
      "published": "2026-02-13T17:33:48Z",
      "updated": "2026-02-13T17:33:48Z",
      "authors": [
        "Huishi Luo",
        "Shuokai Li",
        "Hanchen Yang",
        "Zhongbo Sun",
        "Haojie Ding",
        "Boheng Zhang",
        "Zijia Cai",
        "Renliang Qian",
        "Fan Yang",
        "Tingting Gao",
        "Chenyi Lei",
        "Wenwu Ou",
        "Fuzhen Zhuang"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13134v1",
      "primary_category": "cs.IR",
      "classification": {
        "labs": [
          "Meta AI",
          "Google Research"
        ],
        "topics": [
          "Reasoning"
        ],
        "priority": "medium"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13131v1",
      "title": "Preference-Guided Prompt Optimization for Text-to-Image Generation",
      "summary": "Generative models are increasingly powerful, yet users struggle to guide them through prompts. The generative process is difficult to control and unpredictable, and user instructions may be ambiguous or under-specified. Prior prompt refinement tools heavily rely on human effort, while prompt optimization methods focus on numerical functions and are not designed for human-centered generative tasks, where feedback is better expressed as binary preferences and demands convergence within few iterations. We present APPO, a preference-guided prompt optimization algorithm. Instead of iterating prompts, users only provide binary preferential feedback. APPO adaptively balances its strategies between exploiting user feedback and exploring new directions, yielding effective and efficient optimization. We evaluate APPO on image generation, and the results show APPO enables achieving satisfactory outcomes in fewer iterations with lower cognitive load than manual prompt editing. We anticipate APPO will advance human-AI collaboration in generative tasks by leveraging user preferences to guide complex content creation.",
      "published": "2026-02-13T17:29:04Z",
      "updated": "2026-02-13T17:29:04Z",
      "authors": [
        "Zhipeng Li",
        "Yi-Chi Liao",
        "Christian Holz"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13131v1",
      "primary_category": "cs.HC",
      "classification": {
        "labs": [
          "DeepMind"
        ],
        "topics": [
          "Human-AI Interaction",
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13128v1",
      "title": "Eventizing Traditionally Opaque Binary Neural Networks as 1-safe Petri net Models",
      "summary": "Binary Neural Networks (BNNs) offer a low-complexity and energy-efficient alternative to traditional full-precision neural networks by constraining their weights and activations to binary values. However, their discrete, highly non-linear behavior makes them difficult to explain, validate and formally verify. As a result, BNNs remain largely opaque, limiting their suitability in safety-critical domains, where causal transparency and behavioral guarantees are essential. In this work, we introduce a Petri net (PN)-based framework that captures the BNN's internal operations as event-driven processes. By \"eventizing\" their operations, we expose their causal relationships and dependencies for a fine-grained analysis of concurrency, ordering, and state evolution. Here, we construct modular PN blueprints for core BNN components including activation, gradient computation and weight updates, and compose them into a complete system-level model. We then validate the composed PN against a reference software-based BNN, verify it against reachability and structural checks to establish 1-safeness, deadlock-freeness, mutual exclusion and correct-by-construction causal sequencing, before we assess its scalability and complexity at segment, component, and system levels using the automated measurement tools in Workcraft. Overall, this framework enables causal introspection of transparent and event-driven BNNs that are amenable to formal reasoning and verification.",
      "published": "2026-02-13T17:25:47Z",
      "updated": "2026-02-13T17:25:47Z",
      "authors": [
        "Mohamed Tarraf",
        "Alex Chan",
        "Alex Yakovlev",
        "Rishad Shafik"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13128v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [
          "Reasoning"
        ],
        "priority": "medium"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13126v1",
      "title": "Automating UI Optimization through Multi-Agentic Reasoning",
      "summary": "We present AutoOptimization, a novel multi-objective optimization framework for adapting user interfaces. From a user's verbal preferences for changing a UI, our framework guides a prioritization-based Pareto frontier search over candidate layouts. It selects suitable objective functions for UI placement while simultaneously parameterizing them according to the user's instructions to define the optimization problem. A solver then generates a series of optimal UI layouts, which our framework validates against the user's instructions to adapt the UI with the final solution. Our approach thus overcomes the previous need for manual inspection of layouts and the use of population averages for objective parameters. We integrate multiple agents sequentially within our framework, enabling the system to leverage their reasoning capabilities to interpret user preferences, configure the optimization problem, and validate optimization outcomes.",
      "published": "2026-02-13T17:24:36Z",
      "updated": "2026-02-13T17:24:36Z",
      "authors": [
        "Zhipeng Li",
        "Christoph Gebhardt",
        "Yi-Chi Liao",
        "Christian Holz"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13126v1",
      "primary_category": "cs.HC",
      "classification": {
        "labs": [
          "Anthropic"
        ],
        "topics": [
          "AI Agents & Delegation",
          "Reasoning"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13121v1",
      "title": "LinkedNN: a neural model of linkage disequilibrium decay for recent effective population size inference",
      "summary": "Summary: A bioinformatics tool is presented for estimating recent effective population size by using a neural network to automatically compute linkage disequilibrium-related features as a function of genomic distance between polymorphisms. The new method outperforms existing deep learning and summary statistic-based approaches using relatively few sequenced individuals and variant sites, making it particularly valuable for molecular ecology applications with sparse, unphased data. Availability and implementation: The program is available as an easily installable Python package with documentation here: https://pypi.org/project/linkedNN/. The open source code is available from: https://github.com/the-smith-lab/LinkedNN.",
      "published": "2026-02-13T17:18:21Z",
      "updated": "2026-02-13T17:18:21Z",
      "authors": [
        "Chris C R Smith"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13121v1",
      "primary_category": "q-bio.PE",
      "classification": {
        "labs": [
          "Meta AI"
        ],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13119v1",
      "title": "\"It's More of a Lifestyle'': Design Considerations for Supporting Everyday Practices in Community-Based Farming",
      "summary": "Farming plays a significant role in the economy by supporting related industries such as food, retail, and local services. Community-based small farms, while offering unique social and cultural benefits, face persistent challenges, including limited access to formal education and underdeveloped infrastructure, which have been discussed in prior research. This study focuses on community-driven factors, such as workarounds for recording critical information and practices for passing down farming knowledge across generations. Through 11 semi-structured interviews with farmers from a small ethnic community, the Hmong, we explore how bonding social capital, rooted in close family and community ties, supports informal knowledge exchange and creates pathways to bridging and linking capital. These relationships help farmers connect to broader networks, resources, and institutions. Our findings highlight opportunities for designing technologies that support and strengthen existing support systems. We discuss how technologies should be designed to reflect the cultural values, unique practices, and intergenerational relationships embedded in community-based farms.",
      "published": "2026-02-13T17:16:48Z",
      "updated": "2026-02-13T17:16:48Z",
      "authors": [
        "Minghe Lu",
        "Zhanming Chen",
        "May Sunmin Hwang",
        "Ji Youn Shin"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13119v1",
      "primary_category": "cs.HC",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13108v1",
      "title": "Encoder initialisation methods in the model augmentation setting",
      "summary": "Nonlinear system identification (NL-SI) has proven to be effective in obtaining accurate models for highly complex systems. Recent encoder-based methods for artificial neural network state-space (ANN-SS) models have shown state-of-the-art performance with improved computational efficiency, where the encoder is used to estimate the initial state allowing for batch optimisation methods. To address the lack of interpretability of these black-box ANN models, model augmentation approaches can be used. These combine prior available baseline models with the ANN learning components, resulting in faster convergence and more interpretable models. The combination of the encoder-based method with model augmentation has shown potential. Thus far, however, the encoder has still been treated as a black-box function in the overall estimation process, while additional information in the form of the baseline model is available to predict the model state from past input-output data. In this paper, we propose novel encoder initialisation approaches based on the available baseline model, resulting in improved noise robustness and faster convergence compared to black-box initialisation. The performance of these initialisation methods is demonstrated on a mass-spring-damper system.",
      "published": "2026-02-13T17:10:26Z",
      "updated": "2026-02-13T17:10:26Z",
      "authors": [
        "J. H. Hoekstra",
        "B. Györök",
        "R. Töth",
        "M. Schoukens"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13108v1",
      "primary_category": "eess.SY",
      "classification": {
        "labs": [
          "Anthropic"
        ],
        "topics": [
          "AI Safety & Alignment",
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13106v1",
      "title": "Which Algorithms Can Graph Neural Networks Learn?",
      "summary": "In recent years, there has been growing interest in understanding neural architectures' ability to learn to execute discrete algorithms, a line of work often referred to as neural algorithmic reasoning. The goal is to integrate algorithmic reasoning capabilities into larger neural pipelines. Many such architectures are based on (message-passing) graph neural networks (MPNNs), owing to their permutation equivariance and ability to deal with sparsity and variable-sized inputs. However, existing work is either largely empirical and lacks formal guarantees or it focuses solely on expressivity, leaving open the question of when and how such architectures generalize beyond a finite training set. In this work, we propose a general theoretical framework that characterizes the sufficient conditions under which MPNNs can learn an algorithm from a training set of small instances and provably approximate its behavior on inputs of arbitrary size. Our framework applies to a broad class of algorithms, including single-source shortest paths, minimum spanning trees, and general dynamic programming problems, such as the $0$-$1$ knapsack problem. In addition, we establish impossibility results for a wide range of algorithmic tasks, showing that standard MPNNs cannot learn them, and we derive more expressive MPNN-like architectures that overcome these limitations. Finally, we refine our analysis for the Bellman-Ford algorithm, yielding a substantially smaller required training set and significantly extending the recent work of Nerem et al. [2025] by allowing for a differentiable regularization loss. Empirical results largely support our theoretical findings.",
      "published": "2026-02-13T17:09:50Z",
      "updated": "2026-02-13T17:09:50Z",
      "authors": [
        "Solveig Wittig",
        "Antonis Vasileiou",
        "Robert R. Nerem",
        "Timo Stoll",
        "Floris Geerts",
        "Yusu Wang",
        "Christopher Morris"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13106v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [
          "Reasoning"
        ],
        "priority": "medium"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13104v1",
      "title": "Random Forests as Statistical Procedures: Design, Variance, and Dependence",
      "summary": "Random forests are widely used prediction procedures, yet are typically described algorithmically rather than as statistical designs acting on a fixed dataset. We develop a finite-sample, design-based formulation of random forests in which each tree is an explicit randomized conditional regression function. This perspective yields an exact variance identity for the forest predictor that separates finite-aggregation variability from a structural dependence term that persists even under infinite aggregation. We further decompose both single-tree dispersion and inter-tree covariance using the laws of total variance and covariance, isolating two fundamental design mechanisms-reuse of training observations and alignment of data-adaptive partitions. These mechanisms induce a strict covariance floor, demonstrating that predictive variability cannot be eliminated by increasing the number of trees alone. The resulting framework clarifies how resampling, feature-level randomization, and split selection govern resolution, tree variability, and dependence, and establishes random forests as explicit finite-sample statistical designs whose behavior is determined by their underlying randomized construction.",
      "published": "2026-02-13T17:08:43Z",
      "updated": "2026-02-13T17:08:43Z",
      "authors": [
        "Nathaniel S. O'Connell"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13104v1",
      "primary_category": "stat.ML",
      "classification": {
        "labs": [
          "OpenAI"
        ],
        "topics": [
          "AI Safety & Alignment"
        ],
        "priority": "medium"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13103v1",
      "title": "R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training",
      "summary": "Self-play bootstraps LLM reasoning through an iterative Challenger-Solver loop: the Challenger is trained to generate questions that target the Solver's capabilities, and the Solver is optimized on the generated data to expand its reasoning skills. However, existing frameworks like R-Zero often exhibit non-sustained improvement, where early gains degrade as self-play continues. We identify a key failure mode, Diversity Illusion, where the Solver's training signals appear diverse yet collapse into recurring underlying patterns. It manifests as (1) Local Diversity Illusion, where diversity is enforced only within-batch, inducing cross-iteration mode cycling; and (2) Surface Diversity Illusion, where questions vary superficially but require near-identical reasoning skills. To mitigate them, we propose R-Diverse with two aligned innovations: Memory-Augmented Penalty (MAP), which uses a persistent memory bank to discourage recycling across iterations, and Skill-Aware Measurement (SAM), which evaluates diversity by the reasoning skills exercised rather than surface variation of questions. Across 10 math and general reasoning benchmarks, R-Diverse sustains gains over more iterations and consistently outperforms prior self-play methods. Code is available at https://github.com/Gengsheng-Li/R-Diverse.",
      "published": "2026-02-13T17:07:42Z",
      "updated": "2026-02-13T17:07:42Z",
      "authors": [
        "Gengsheng Li",
        "Jinghan He",
        "Shijie Wang",
        "Dan Zhang",
        "Ruiqi Liu",
        "Renrui Zhang",
        "Zijun Yao",
        "Junfeng Fang",
        "Haiyun Guo",
        "Jinqiao Wang"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13103v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Anthropic",
          "Meta AI"
        ],
        "topics": [
          "Reasoning"
        ],
        "priority": "medium"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13102v1",
      "title": "Towards interpretable models for language proficiency assessment: Predicting the CEFR level of Estonian learner texts",
      "summary": "Using NLP to analyze authentic learner language helps to build automated assessment and feedback tools. It also offers new and extensive insights into the development of second language production. However, there is a lack of research explicitly combining these aspects. This study aimed to classify Estonian proficiency examination writings (levels A2-C1), assuming that careful feature selection can lead to more explainable and generalizable machine learning models for language testing. Various linguistic properties of the training data were analyzed to identify relevant proficiency predictors associated with increasing complexity and correctness, rather than the writing task. Such lexical, morphological, surface, and error features were used to train classification models, which were compared to models that also allowed for other features. The pre-selected features yielded a similar test accuracy but reduced variation in the classification of different text types. The best classifiers achieved an accuracy of around 0.9. Additional evaluation on an earlier exam sample revealed that the writings have become more complex over a 7-10-year period, while accuracy still reached 0.8 with some feature sets. The results have been implemented in the writing evaluation module of an Estonian open-source language learning environment.",
      "published": "2026-02-13T17:06:17Z",
      "updated": "2026-02-13T17:06:17Z",
      "authors": [
        "Kais Allkivi"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13102v1",
      "primary_category": "cs.CL",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13098v1",
      "title": "Barron-Wiener-Laguerre models",
      "summary": "We propose a probabilistic extension of Wiener-Laguerre models for causal operator learning. Classical Wiener-Laguerre models parameterize stable linear dynamics using orthonormal Laguerre bases and apply a static nonlinear map to the resulting features. While structurally efficient and interpretable, they provide only deterministic point estimates. We reinterpret the nonlinear component through the lens of Barron function approximation, viewing two-layer networks, random Fourier features, and extreme learning machines as discretizations of integral representations over parameter measures. This perspective naturally admits Bayesian inference on the nonlinear map and yields posterior predictive uncertainty. By combining Laguerre-parameterized causal dynamics with probabilistic Barron-type nonlinear approximators, we obtain a structured yet expressive class of causal operators equipped with uncertainty quantification. The resulting framework bridges classical system identification and modern measure-based function approximation, providing a principled approach to time-series modeling and nonlinear systems identification.",
      "published": "2026-02-13T17:02:48Z",
      "updated": "2026-02-13T17:02:48Z",
      "authors": [
        "Rahul Manavalan",
        "Filip Tronarp"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13098v1",
      "primary_category": "stat.ME",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13093v1",
      "title": "Consistency of Large Reasoning Models Under Multi-Turn Attacks",
      "summary": "Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.",
      "published": "2026-02-13T16:58:47Z",
      "updated": "2026-02-13T16:58:47Z",
      "authors": [
        "Yubo Li",
        "Ramayya Krishnan",
        "Rema Padman"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13093v1",
      "primary_category": "cs.AI",
      "classification": {
        "labs": [],
        "topics": [
          "Reasoning"
        ],
        "priority": "medium"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13088v1",
      "title": "How cyborg propaganda reshapes collective action",
      "summary": "The distinction between genuine grassroots activism and automated influence operations is collapsing. While policy debates focus on bot farms, a distinct threat to democracy is emerging via partisan coordination apps and artificial intelligence-what we term 'cyborg propaganda.' This architecture combines large numbers of verified humans with adaptive algorithmic automation, enabling a closed-loop system. AI tools monitor online sentiment to optimize directives and generate personalized content for users to post online. Cyborg propaganda thereby exploits a critical legal shield: by relying on verified citizens to ratify and disseminate messages, these campaigns operate in a regulatory gray zone, evading liability frameworks designed for automated botnets. We explore the collective action paradox of this technology: does it democratize power by 'unionizing' influence (pooling the reach of dispersed citizens to overcome the algorithmic invisibility of isolated voices), or does it reduce citizens to 'cognitive proxies' of a central directive? We argue that cyborg propaganda fundamentally alters the digital public square, shifting political discourse from a democratic contest of individual ideas to a battle of algorithmic campaigns. We outline a research agenda to distinguish organic from coordinated information diffusion and propose governance frameworks to address the regulatory challenges of AI-assisted collective expression.",
      "published": "2026-02-13T16:49:26Z",
      "updated": "2026-02-13T16:49:26Z",
      "authors": [
        "Jonas R. Kunst",
        "Kinga Bierwiaczonek",
        "Meeyoung Cha",
        "Omid V. Ebrahimi",
        "Marc Fawcett-Atkinson",
        "Asbjørn Følstad",
        "Anton Gollwitzer",
        "Nils Köbis",
        "Gary Marcus",
        "Jon Roozenbeek",
        "Daniel Thilo Schroeder",
        "Jay J. Van Bavel",
        "Sander van der Linden",
        "Rory White",
        "Live Leonhardsen Wilhelmsen"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13088v1",
      "primary_category": "cs.CY",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13087v1",
      "title": "EXCODER: EXplainable Classification Of DiscretE time series Representations",
      "summary": "Deep learning has significantly improved time series classification, yet the lack of explainability in these models remains a major challenge. While Explainable AI (XAI) techniques aim to make model decisions more transparent, their effectiveness is often hindered by the high dimensionality and noise present in raw time series data. In this work, we investigate whether transforming time series into discrete latent representations-using methods such as Vector Quantized Variational Autoencoders (VQ-VAE) and Discrete Variational Autoencoders (DVAE)-not only preserves but enhances explainability by reducing redundancy and focusing on the most informative patterns. We show that applying XAI methods to these compressed representations leads to concise and structured explanations that maintain faithfulness without sacrificing classification performance. Additionally, we propose Similar Subsequence Accuracy (SSA), a novel metric that quantitatively assesses the alignment between XAI-identified salient subsequences and the label distribution in the training data. SSA provides a systematic way to validate whether the features highlighted by XAI methods are truly representative of the learned classification patterns. Our findings demonstrate that discrete latent representations not only retain the essential characteristics needed for classification but also offer a pathway to more compact, interpretable, and computationally efficient explanations in time series analysis.",
      "published": "2026-02-13T16:47:45Z",
      "updated": "2026-02-13T16:47:45Z",
      "authors": [
        "Yannik Hahn",
        "Antonin Königsfeld",
        "Hasan Tercan",
        "Tobias Meisen"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13087v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "OpenAI"
        ],
        "topics": [
          "AI Safety & Alignment",
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13086v1",
      "title": "UniManip: General-Purpose Zero-Shot Robotic Manipulation with Agentic Operational Graph",
      "summary": "Achieving general-purpose robotic manipulation requires robots to seamlessly bridge high-level semantic intent with low-level physical interaction in unstructured environments. However, existing approaches falter in zero-shot generalization: end-to-end Vision-Language-Action (VLA) models often lack the precision required for long-horizon tasks, while traditional hierarchical planners suffer from semantic rigidity when facing open-world variations. To address this, we present UniManip, a framework grounded in a Bi-level Agentic Operational Graph (AOG) that unifies semantic reasoning and physical grounding. By coupling a high-level Agentic Layer for task orchestration with a low-level Scene Layer for dynamic state representation, the system continuously aligns abstract planning with geometric constraints, enabling robust zero-shot execution. Unlike static pipelines, UniManip operates as a dynamic agentic loop: it actively instantiates object-centric scene graphs from unstructured perception, parameterizes these representations into collision-free trajectories via a safety-aware local planner, and exploits structured memory to autonomously diagnose and recover from execution failures. Extensive experiments validate the system's robust zero-shot capability on unseen objects and tasks, demonstrating a 22.5% and 25.0% higher success rate compared to state-of-the-art VLA and hierarchical baselines, respectively. Notably, the system enables direct zero-shot transfer from fixed-base setups to mobile manipulation without fine-tuning or reconfiguration. Our open-source project page can be found at https://henryhcliu.github.io/unimanip.",
      "published": "2026-02-13T16:47:26Z",
      "updated": "2026-02-13T16:47:26Z",
      "authors": [
        "Haichao Liu",
        "Yuanjiang Xue",
        "Yuheng Zhou",
        "Haoyuan Deng",
        "Yinan Liang",
        "Lihua Xie",
        "Ziwei Wang"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13086v1",
      "primary_category": "cs.RO",
      "classification": {
        "labs": [],
        "topics": [
          "AI Agents & Delegation",
          "Reasoning"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13081v1",
      "title": "Agentic AI for Robot Control: Flexible but still Fragile",
      "summary": "Recent work leverages the capabilities and commonsense priors of generative models for robot control. In this paper, we present an agentic control system in which a reasoning-capable language model plans and executes tasks by selecting and invoking robot skills within an iterative planner and executor loop. We deploy the system on two physical robot platforms in two settings: (i) tabletop grasping, placement, and box insertion in indoor mobile manipulation (Mobipick) and (ii) autonomous agricultural navigation and sensing (Valdemar). Both settings involve uncertainty, partial observability, sensor noise, and ambiguous natural-language commands. The system exposes structured introspection of its planning and decision process, reacts to exogenous events via explicit event checks, and supports operator interventions that modify or redirect ongoing execution. Across both platforms, our proof-of-concept experiments reveal substantial fragility, including non-deterministic suboptimal behavior, instruction-following errors, and high sensitivity to prompt specification. At the same time, the architecture is flexible: transfer to a different robot and task domain largely required updating the system prompt (domain model, affordances, and action catalogue) and re-binding the same tool interface to the platform-specific skill API.",
      "published": "2026-02-13T16:43:34Z",
      "updated": "2026-02-13T16:43:34Z",
      "authors": [
        "Oscar Lima",
        "Marc Vinci",
        "Martin Günther",
        "Marian Renz",
        "Alexander Sung",
        "Sebastian Stock",
        "Johannes Brust",
        "Lennart Niecksch",
        "Zongyao Yi",
        "Felix Igelbrink",
        "Benjamin Kisliuk",
        "Martin Atzmueller",
        "Joachim Hertzberg"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13081v1",
      "primary_category": "cs.RO",
      "classification": {
        "labs": [
          "DeepMind",
          "Google Research"
        ],
        "topics": [
          "AI Agents & Delegation",
          "Reasoning"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13078v1",
      "title": "SENSE-STEP: Learning Sim-to-Real Locomotion for a Sensory-Enabled Soft Quadruped Robot",
      "summary": "Robust closed-loop locomotion remains challenging for soft quadruped robots due to high-dimensional dynamics, actuator hysteresis, and difficult-to-model contact interactions, while conventional proprioception provides limited information about ground contact. In this paper, we present a learning-based control framework for a pneumatically actuated soft quadruped equipped with tactile suction-cup feet, and we validate the approach experimentally on physical hardware. The control policy is trained in simulation through a staged learning process that starts from a reference gait and is progressively refined under randomized environmental conditions. The resulting controller maps proprioceptive and tactile feedback to coordinated pneumatic actuation and suction-cup commands, enabling closed-loop locomotion on flat and inclined surfaces. When deployed on the real robot, the closed-loop policy outperforms an open-loop baseline, increasing forward speed by 41% on a flat surface and by 91% on a 5-degree incline. Ablation studies further demonstrate the role of tactile force estimates and inertial feedback in stabilizing locomotion, with performance improvements of up to 56% compared to configurations without sensory feedback.",
      "published": "2026-02-13T16:37:29Z",
      "updated": "2026-02-13T16:37:29Z",
      "authors": [
        "Storm de Kam",
        "Ebrahim Shahabi",
        "Cosimo Della Santina"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13078v1",
      "primary_category": "cs.RO",
      "classification": {
        "labs": [],
        "topics": [
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13073v1",
      "title": "LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning",
      "summary": "Memory-efficient backpropagation (MeBP) has enabled first-order fine-tuning of large language models (LLMs) on mobile devices with less than 1GB memory. However, MeBP requires backward computation through all transformer layers at every step, where weight decompression alone accounts for 32--42% of backward time. We propose Layer-Cyclic Selective Backpropagation (LCSB), which computes gradients for only a subset of layers per step. Our key insight is that residual connections guarantee gradient flow through identity paths, while AdamW momentum provides implicit updates for non-selected layers. We interpret LCSB as Block Coordinate Descent on the LoRA parameter space, providing theoretical justification for convergence. LCSB achieves up to 1.40$\\times$ speedup with less than 2\\% quality degradation across five models and three tasks. Surprisingly, in 4-bit quantized settings, LCSB exhibits superior stability: a 3B model that completely diverges under full backpropagation converges smoothly with LCSB, suggesting an implicit regularization effect from selective gradient computation.",
      "published": "2026-02-13T16:32:53Z",
      "updated": "2026-02-13T16:32:53Z",
      "authors": [
        "Juneyoung Park",
        "Eunbeen Yoon",
        "Seongwan Kim. Jaeho Lee"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13073v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [],
        "priority": "low"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13071v1",
      "title": "Bus-Conditioned Zero-Shot Trajectory Generation via Task Arithmetic",
      "summary": "Mobility trajectory data provide essential support for smart city applications. However, such data are often difficult to obtain. Meanwhile, most existing trajectory generation methods implicitly assume that at least a subset of real mobility data from target city is available, which limits their applicability in data-inaccessible scenarios. In this work, we propose a new problem setting, called bus-conditioned zero-shot trajectory generation, where no mobility trajectories from a target city are accessible. The generation process relies solely on source city mobility data and publicly available bus timetables from both cities. Under this setting, we propose MobTA, the first approach to introduce task arithmetic into trajectory generation. MobTA models the parameter shift from bus-timetable-based trajectory generation to mobility trajectory generation in source city, and applies this shift to target city through arithmetic operations on task vectors. This enables trajectory generation that reflects target-city mobility patterns without requiring any real mobility data from it. Furthermore, we theoretically analyze MobTA's stability across base and instruction-tuned LLMs. Extensive experiments show that MobTA significantly outperforms existing methods, and achieves performance close to models finetuned using target city mobility trajectories.",
      "published": "2026-02-13T16:30:21Z",
      "updated": "2026-02-13T16:30:21Z",
      "authors": [
        "Shuai Liu",
        "Ning Cao",
        "Yile Chen",
        "Yue Jiang",
        "Gao Cong"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13071v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [],
        "priority": "low"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13069v1",
      "title": "Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning",
      "summary": "On-device fine-tuning enables privacy-preserving personalization of large language models, but mobile devices impose severe memory constraints, typically 6--12GB shared across all workloads. Existing approaches force a trade-off between exact gradients with high memory (MeBP) and low memory with noisy estimates (MeZO). We propose Memory-efficient Structured Backpropagation (MeSP), which bridges this gap by manually deriving backward passes that exploit LoRA's low-rank structure. Our key insight is that the intermediate projection $h = xA$ can be recomputed during backward at minimal cost since rank $r \\ll d_{in}$, eliminating the need to store it. MeSP achieves 49\\% average memory reduction compared to MeBP on Qwen2.5 models (0.5B--3B) while computing mathematically identical gradients. Our analysis also reveals that MeZO's gradient estimates show near-zero correlation with true gradients (cosine similarity $\\approx$0.001), explaining its slow convergence. MeSP reduces peak memory from 361MB to 136MB for Qwen2.5-0.5B, enabling fine-tuning scenarios previously infeasible on memory-constrained devices.",
      "published": "2026-02-13T16:24:33Z",
      "updated": "2026-02-13T16:24:33Z",
      "authors": [
        "Juneyoung Park",
        "Yuri Hong",
        "Seongwan Kim",
        "Jaeho Lee"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13069v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [],
        "priority": "low"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13067v1",
      "title": "SIEFormer: Spectral-Interpretable and -Enhanced Transformer for Generalized Category Discovery",
      "summary": "This paper presents a novel approach, Spectral-Interpretable and -Enhanced Transformer (SIEFormer), which leverages spectral analysis to reinterpret the attention mechanism within Vision Transformer (ViT) and enhance feature adaptability, with particular emphasis on challenging Generalized Category Discovery (GCD) tasks. The proposed SIEFormer is composed of two main branches, each corresponding to an implicit and explicit spectral perspective of the ViT, enabling joint optimization. The implicit branch realizes the use of different types of graph Laplacians to model the local structure correlations of tokens, along with a novel Band-adaptive Filter (BaF) layer that can flexibly perform both band-pass and band-reject filtering. The explicit branch, on the other hand, introduces a Maneuverable Filtering Layer (MFL) that learns global dependencies among tokens by applying the Fourier transform to the input ``value\" features, modulating the transformed signal with a set of learnable parameters in the frequency domain, and then performing an inverse Fourier transform to obtain the enhanced features. Extensive experiments reveal state-of-the-art performance on multiple image recognition datasets, reaffirming the superiority of our approach through ablation studies and visualizations.",
      "published": "2026-02-13T16:22:31Z",
      "updated": "2026-02-13T16:22:31Z",
      "authors": [
        "Chunming Li",
        "Shidong Wang",
        "Tong Xin",
        "Haofeng Zhang"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13067v1",
      "primary_category": "cs.CV",
      "classification": {
        "labs": [
          "Google Research"
        ],
        "topics": [],
        "priority": "low"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13062v1",
      "title": "Backdoor Attacks on Contrastive Continual Learning for IoT Systems",
      "summary": "The Internet of Things (IoT) systems increasingly depend on continual learning to adapt to non-stationary environments. These environments can include factors such as sensor drift, changing user behavior, device aging, and adversarial dynamics. Contrastive continual learning (CCL) combines contrastive representation learning with incremental adaptation, enabling robust feature reuse across tasks and domains. However, the geometric nature of contrastive objectives, when paired with replay-based rehearsal and stability-preserving regularization, introduces new security vulnerabilities. Notably, backdoor attacks can exploit embedding alignment and replay reinforcement, enabling the implantation of persistent malicious behaviors that endure through updates and deployment cycles. This paper provides a comprehensive analysis of backdoor attacks on CCL within IoT systems. We formalize the objectives of embedding-level attacks, examine persistence mechanisms unique to IoT deployments, and develop a layered taxonomy tailored to IoT. Additionally, we compare vulnerabilities across various learning paradigms and evaluate defense strategies under IoT constraints, including limited memory, edge computing, and federated aggregation. Our findings indicate that while CCL is effective for enhancing adaptive IoT intelligence, it may also elevate long-lived representation-level threats if not adequately secured.",
      "published": "2026-02-13T16:17:25Z",
      "updated": "2026-02-13T16:17:25Z",
      "authors": [
        "Alfous Tim",
        "Kuniyilh Simi D"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13062v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "DeepMind",
          "OpenAI"
        ],
        "topics": [
          "AI Safety & Alignment",
          "Learning & Education"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13059v1",
      "title": "TraceBack: Multi-Agent Decomposition for Fine-Grained Table Attribution",
      "summary": "Question answering (QA) over structured tables requires not only accurate answers but also transparency about which cells support them. Existing table QA systems rarely provide fine-grained attribution, so even correct answers often lack verifiable grounding, limiting trust in high-stakes settings. We address this with TraceBack, a modular multi-agent framework for scalable, cell-level attribution in single-table QA. TraceBack prunes tables to relevant rows and columns, decomposes questions into semantically coherent sub-questions, and aligns each answer span with its supporting cells, capturing both explicit and implicit evidence used in intermediate reasoning steps. To enable systematic evaluation, we release CITEBench, a benchmark with phrase-to-cell annotations drawn from ToTTo, FetaQA, and AITQA. We further propose FairScore, a reference-less metric that compares atomic facts derived from predicted cells and answers to estimate attribution precision and recall without human cell labels. Experiments show that TraceBack substantially outperforms strong baselines across datasets and granularities, while FairScore closely tracks human judgments and preserves relative method rankings, supporting interpretable and scalable evaluation of table-based QA.",
      "published": "2026-02-13T16:13:36Z",
      "updated": "2026-02-13T16:13:36Z",
      "authors": [
        "Tejas Anvekar",
        "Junha Park",
        "Rajat Jha",
        "Devanshu Gupta",
        "Poojah Ganesan",
        "Puneeth Mathur",
        "Vivek Gupta"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13059v1",
      "primary_category": "cs.CL",
      "classification": {
        "labs": [
          "Anthropic"
        ],
        "topics": [
          "AI Agents & Delegation",
          "Reasoning"
        ],
        "priority": "high"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13177v1",
      "title": "Improved Regret Guarantees for Online Mirror Descent using a Portfolio of Mirror Maps",
      "summary": "OMD and its variants give a flexible framework for OCO where the performance depends crucially on the choice of the mirror map. While the geometries underlying OPGD and OEG, both special cases of OMD, are well understood, it remains a challenging open question on how to construct an optimal mirror map for any given constrained set and a general family of loss functions, e.g., sparse losses. Motivated by parameterizing a near-optimal set of mirror maps, we consider a simpler question: is it even possible to obtain polynomial gains in regret by using mirror maps for geometries that interpolate between $L_1$ and $L_2$, which may not be possible by restricting to only OEG ($L_1$) or OPGD ($L_2$).\n  Our main result answers this question positively. We show that mirror maps based on block norms adapt better to the sparsity of loss functions, compared to previous $L_p$ (for $p \\in [1, 2]$) interpolations. In particular, we construct a family of online convex optimization instances in $\\mathbb{R}^d$, where block norm-based mirror maps achieve a provable polynomial (in $d$) improvement in regret over OEG and OPGD for sparse loss functions. We then turn to the setting in which the sparsity level of the loss functions is unknown. In this case, the choice of geometry itself becomes an online decision problem. We first show that naively switching between OEG and OPGD can incur linear regret, highlighting the intrinsic difficulty of geometry selection. To overcome this issue, we propose a meta-algorithm based on multiplicative weights that dynamically selects among a family of uniform block norms. We show that this approach effectively tunes OMD to the sparsity of the losses, yielding adaptive regret guarantees. Overall, our results demonstrate that online mirror-map selection can significantly enhance the ability of OMD to exploit sparsity in online convex optimization.",
      "published": "2026-02-13T18:37:26Z",
      "updated": "2026-02-13T18:37:26Z",
      "authors": [
        "Swati Gupta",
        "Jai Moondra",
        "Mohit Singh"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13177v1",
      "primary_category": "math.OC",
      "classification": {
        "labs": [
          "01.AI (零一万物)"
        ],
        "topics": [],
        "priority": "low"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13075v1",
      "title": "Unified Multi-Domain Graph Pre-training for Homogeneous and Heterogeneous Graphs via Domain-Specific Expert Encoding",
      "summary": "Graph pre-training has achieved remarkable success in recent years, delivering transferable representations for downstream adaptation. However, most existing methods are designed for either homogeneous or heterogeneous graphs, thereby hindering unified graph modeling across diverse graph types. This separation contradicts real-world applications, where mixed homogeneous and heterogeneous graphs are ubiquitous, and distribution shifts between upstream pre-training and downstream deployment are common. In this paper, we empirically demonstrate that a balanced mixture of homogeneous and heterogeneous graph pre-training benefits downstream tasks and propose a unified multi-domain \\textbf{G}raph \\textbf{P}re-training method across \\textbf{H}omogeneous and \\textbf{H}eterogeneous graphs ($\\mathbf{GPH^{2}}$). To address the lack of a unified encoder for homogeneous and heterogeneous graphs, we propose a Unified Multi-View Graph Construction that simultaneously encodes both without explicit graph-type-specific designs. To cope with the increased cross-domain distribution discrepancies arising from mixed graphs, we introduce domain-specific expert encoding. Each expert is independently pre-trained on a single graph to capture domain-specific knowledge, thereby shielding the pre-training encoder from the adverse effects of cross-domain discrepancies. For downstream tasks, we further design a Task-oriented Expert Fusion Strategy that adaptively integrates multiple experts based on their discriminative strengths. Extensive experiments on mixed graphs demonstrate that $\\text{GPH}^{2}$ enables stable transfer across graph types and domains, significantly outperforming existing graph pre-training methods.",
      "published": "2026-02-13T16:34:55Z",
      "updated": "2026-02-13T16:34:55Z",
      "authors": [
        "Chundong Liang",
        "Yongqi Huang",
        "Dongxiao He",
        "Peiyuan Li",
        "Yawen Li",
        "Di Jin",
        "Weixiong Zhang"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13075v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "DeepSeek (深度求索)",
          "Moonshot AI (月之暗面)"
        ],
        "topics": [],
        "priority": "low"
      }
    },
    {
      "id": "http://arxiv.org/abs/2602.13061v1",
      "title": "Diverging Flows: Detecting Extrapolations in Conditional Generation",
      "summary": "The ability of Flow Matching (FM) to model complex conditional distributions has established it as the state-of-the-art for prediction tasks (e.g., robotics, weather forecasting). However, deployment in safety-critical settings is hindered by a critical extrapolation hazard: driven by smoothness biases, flow models yield plausible outputs even for off-manifold conditions, resulting in silent failures indistinguishable from valid predictions. In this work, we introduce Diverging Flows, a novel approach that enables a single model to simultaneously perform conditional generation and native extrapolation detection by structurally enforcing inefficient transport for off-manifold inputs. We evaluate our method on synthetic manifolds, cross-domain style transfer, and weather temperature forecasting, demonstrating that it achieves effective detection of extrapolations without compromising predictive fidelity or inference latency. These results establish Diverging Flows as a robust solution for trustworthy flow models, paving the way for reliable deployment in domains such as medicine, robotics, and climate science.",
      "published": "2026-02-13T16:15:58Z",
      "updated": "2026-02-13T16:15:58Z",
      "authors": [
        "Constantinos Tsakonas",
        "Serena Ivaldi",
        "Jean-Baptiste Mouret"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.13061v1",
      "primary_category": "cs.LG",
      "classification": {
        "labs": [
          "01.AI (零一万物)"
        ],
        "topics": [],
        "priority": "low"
      }
    }
  ],
  "last_check": "2026-02-16T14:01:26.153957"
}